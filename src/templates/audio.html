<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>CleanMeet AI</title>
  <style>
    /* Root Styles */
    body {
      display: flex;
      flex-direction: column;
      align-items: center;
      justify-content: center;
      min-height: 100vh;
      background: linear-gradient(135deg, #232121, #232121, #232121);
      color: #fff;
      font-family: 'Roboto', sans-serif;
      margin: 0;
      padding: 0 15px;
    }

    /* Header */
    .header {
      width: 100%;
      padding: 20px;
      background: rgba(98, 93, 93, 0.9);
      color: #fff;
      display: flex;
      align-items: center;
      justify-content: center;
      box-shadow: 0 4px 8px rgba(0, 0, 0, 0.3);
      position: sticky;
      top: 0;
      z-index: 1000;
    }

    .header h1 {
      font-size: 2rem;
      font-weight: bold;
      margin: 0;
      letter-spacing: 2px;
    }

    /* Main Container */
    .container {
      display: grid;
      grid-template-columns: 1fr 1fr;
      gap: 30px;
      align-items: start;
      width: 100%;
      max-width: 1200px;
      margin-top: 40px;
    }

    .video-section {
      display: flex;
      flex-direction: column;
      align-items: center;
    }

    video {
      border: 4px solid rgba(255, 255, 255, 0.3);
      border-radius: 16px;
      width: 100%;
      aspect-ratio: 16 / 9;
      box-shadow: 0px 6px 20px rgba(0, 0, 0, 0.6);
      background-color: #000;
    }

    canvas {
      display: none;
    }

    .status-container {
      display: flex;
      flex-direction: column;
      gap: 20px;
      margin-top: 20px;
      width: 100%;
    }

    .status {
      font-size: 1.3rem;
      text-align: center;
      padding: 15px;
      border-radius: 10px;
      background-color: rgba(255, 255, 255, 0.1);
      box-shadow: 0px 4px 12px rgba(255, 255, 255, 0.1);
    }

    .status.positive {
      color: #4caf50;
    }

    .status.negative {
      color: #ff5252;
    }

    /* Control Section */
    .controls {
      display: flex;
      flex-direction: column;
      align-items: center;
      gap: 20px;
    }

    .button-container {
      display: flex;
      gap: 15px;
      flex-wrap: wrap;
    }

    .button-container button {
      padding: 12px 24px;
      font-size: 1rem;
      border: none;
      border-radius: 8px;
      cursor: pointer;
      color: #fff;
      background: linear-gradient(90deg, #ff416c, #ff4b2b);
      transition: transform 0.2s, box-shadow 0.2s;
      box-shadow: 0px 4px 12px rgba(255, 75, 43, 0.4);
    }

    .button-container button:hover {
      transform: scale(1.05);
      box-shadow: 0px 6px 15px rgba(255, 75, 43, 0.6);
    }

    .button-container button:disabled {
      background: #555;
      cursor: not-allowed;
      box-shadow: none;
    }

    /* Footer */
    footer {
      margin-top: 40px;
      font-size: 0.9rem;
      color: #bbb;
      text-align: center;
    }
  </style>
</head>
<body>
  <div class="header">
    <h1>CleanMeet AI</h1>
  </div>

  <div class="container">
    <!-- Video Section -->
    <div class="video-section">
      <video id="video" autoplay muted></video>
      <canvas id="canvas"></canvas>
      <div class="status-container">
        <div id="status" class="status">Waiting for detection...</div>
        <div id="status1" class="status">Waiting for detection...</div>
      </div>
    </div>

    <!-- Controls Section -->
    <div class="controls">
      <div class="button-container">
        <button id="startButton">Start Recording</button>
        <button id="stopButton" disabled>Stop Recording</button>
       
      </div>
    </div>
  </div>



  <script>
    const video = document.getElementById("video");
    const canvas = document.getElementById("canvas");
    const statusDiv = document.getElementById("status");
    const status1Div = document.getElementById("status1");
    const startButton = document.getElementById("startButton");
    const stopButton = document.getElementById("stopButton");
    const endCallButton = document.getElementById("endCallButton");

    let mediaRecorder;
    let audioChunks = [];
    let socket;
    let intervalId;

    // Initialize video and WebSocket stream
    async function startStream() {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ video: true, audio: true });
        video.srcObject = stream;

        // Create WebSocket connection to FastAPI backend
        socket = new WebSocket("ws://localhost:8000/wsaudio");

        socket.onopen = () => {
          console.log("WebSocket connected.");
        };

        socket.onmessage = (event) => {
          console.log("Message received from server:", event.data);
          if (event.data === "toxic") {
            status1Div.textContent = "⚠️ Offensive Audio Detected!";
            status1Div.className = "status negative";
          } else {
            status1Div.textContent = "✅ Audio is Safe";
            status1Div.className = "status positive";
          }
        };

        socket.onclose = () => {
          console.log("WebSocket connection closed.");
        };

        // Initialize media recorder for audio
        mediaRecorder = new MediaRecorder(stream);
        mediaRecorder.ondataavailable = (event) => {
          if (event.data.size > 0) {
            audioChunks.push(event.data);
          }
        };

        mediaRecorder.onstop = sendAudio;
        mediaRecorder.start();
        intervalId = setInterval(() => {
          mediaRecorder.stop();
          mediaRecorder.start();
        }, 5000); // Capture audio every 5 seconds

        startButton.disabled = true;
        stopButton.disabled = false;
      } catch (err) {
        console.error("Error accessing media devices:", err);
      }
    }

    // Stop the recording
    function stopRecording() {
      clearInterval(intervalId);
      mediaRecorder.stop();
      startButton.disabled = false;
      stopButton.disabled = true;
    }

    // Send captured audio to backend via WebSocket
    async function sendAudio() {
      const audioBlob = new Blob(audioChunks, { type: "audio/wav" });
      console.log("Sending audio data to backend...");

      try {
        if (socket.readyState === WebSocket.OPEN) {
          socket.send(audioBlob);
          console.log("Audio sent to server.");
          audioChunks = []; // Clear audio chunks for the next recording
        }
      } catch (err) {
        console.error("Error sending audio:", err);
      }
    }

    // Capture video frames and send to backend for NSFW detection
    async function captureFrame() {
      const context = canvas.getContext("2d");
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      context.drawImage(video, 0, 0, canvas.width, canvas.height);

      const blob = await new Promise(resolve => canvas.toBlob(resolve, "image/jpeg"));
      const formData = new FormData();
      formData.append("file", blob, "frame.jpg");

      try {
        const response = await fetch("http://localhost:8000/detect-nsfw", {
          method: "POST",
          body: formData,
        });
        const data = await response.json();

        if (data === "nsfw") {
          statusDiv.textContent = "⚠️ NSFW Video Content Detected!";
          statusDiv.className = "status negative";
        } else {
          statusDiv.textContent = "✅ Video Content is Safe";
          statusDiv.className = "status positive";
        }
      } catch (err) {
        console.error("Error detecting NSFW in video:", err);
      }
    }

    // Start the detection process
    function startDetection() {
      setInterval(captureFrame, 2000); // Capture video frames every 2 seconds
    }

    // Event listeners for buttons
    startButton.addEventListener("click", startStream);
    stopButton.addEventListener("click", stopRecording);

    // Initialize the detection
    startDetection();
  </script>
</body>
</html>
